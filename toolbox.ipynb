{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toolbox.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import 목록"
      ],
      "metadata": {
        "id": "OuJhVefdtkZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "mpl.rc('font', size = 15)\n",
        "plt.figure(figsize=(7,6))\n",
        "\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "z6HzhBs3tmT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 구글 드라이브 연동"
      ],
      "metadata": {
        "id": "WCuES3hrzPD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Upvvxe3IzOmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data handling"
      ],
      "metadata": {
        "id": "bvK50sUF1vED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 프레임 타입별로 분리 요약"
      ],
      "metadata": {
        "id": "VjqaG40I1vEE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6XVQBY_1vEE"
      },
      "outputs": [],
      "source": [
        "a = df.columns.to_series().groupby(df.dtypes).groups\n",
        "for i,v in a.items():\n",
        "    print(i,v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피처요약표"
      ],
      "metadata": {
        "id": "BGN4cGzIUSJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resumetable(df):\n",
        "    print(f'데이터셋 형상 : {df.shape}')\n",
        "    summary = pd.DataFrame(df.dtypes, columns=['데이터타입']) #.sort_values()\n",
        "    #summary = summary.reset_index()\n",
        "    #summary = summary.rename(columns = {'index':'피처'})\n",
        "\n",
        "    #summary['결측치 개수'] = df.isnull().sum().values #결측치가 존재하지 않더라도 -1같은 값으로 있는 경우가 있으니 확인 필요!\n",
        "    \n",
        "    summary['결측치 개수'] = (df == -1).sum().values # 피처별 -1 개수\n",
        "\n",
        "    summary['고윳값 개수'] = df.nunique().values\n",
        "    # summary['첫 번째 값'] = df.loc[0].values\n",
        "    # summary['두 번째 값'] = df.loc[1].values\n",
        "    # summary['세 번째 값'] = df.loc[2].values\n",
        "\n",
        "    for col in df.columns: \n",
        "        \n",
        "        if 'bin' in col or col == 'target':\n",
        "            summary.loc[col, '데이터 종류'] = '이진형'\n",
        "        elif 'cat' in col:\n",
        "            summary.loc[col, '데이터 종류'] = '명목형'\n",
        "        elif df[col].dtype == float:\n",
        "            summary.loc[col, '데이터 종류'] = '연속형'\n",
        "        elif df[col].dtype == int:\n",
        "            summary.loc[col, '데이터 종류'] = '순서형'\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "jRRWzoyf1vEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##read_data"
      ],
      "metadata": {
        "id": "9QMyPuvO1vEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/data/porto-seguro-safe-driver-prediction'\n",
        "\n",
        "files = glob.glob(path + '/*.csv')\n",
        "for file in files:\n",
        "    if 'train' in file:\n",
        "        train = pd.read_csv(file)\n",
        "    elif 'test' in file:\n",
        "        test = pd.read_csv(file)\n",
        "    elif 'sample' in file:\n",
        "        sub = pd.read_csv(file)\n",
        "train.shape, test.shape, sub.shape"
      ],
      "metadata": {
        "id": "_YCN2OCm1vEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##메모리관리 downcast, gc"
      ],
      "metadata": {
        "id": "EHlTVwbCpbUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del group\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "AKsPITdNpcmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downcast(df, verbose=True):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        dtype_name = df[col].dtype.name\n",
        "        if dtype_name == 'object':\n",
        "            pass\n",
        "        elif dtype_name == 'bool':\n",
        "            df[col] = df[col].astype('int8')\n",
        "        elif dtype_name.startswith('int') or (df[col].round() == df[col]).all():\n",
        "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
        "        else:\n",
        "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose:\n",
        "        print('{:.1f}% 압축됨'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "wFb_Brn0pdMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시각화"
      ],
      "metadata": {
        "id": "_uZhtHiv1N4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## subplot ax 사용법"
      ],
      "metadata": {
        "id": "I8Hz_eqOLl-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure, ax= plt.subplots() \n",
        "figure.set_size_inches(11, 5)\n",
        "\n",
        "sns.barplot(x='x', y='y', data=data)\n",
        "\n",
        "ax.set(title='Distribution of total item counts by item category id',\n",
        "       xlabel='Item category ID', \n",
        "       ylabel='Total item counts')\n",
        "ax.tick_params(axis='x', labelrotation=90) # x축 라벨 회전"
      ],
      "metadata": {
        "id": "zV65PNvOLqG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##target에 대한 정규성 검증 qqplot 함수"
      ],
      "metadata": {
        "id": "zKDYsUU75ROQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sapiro Normality Test\n",
        "from scipy import stats\n",
        "#qqplot \n",
        "from scipy.stats import probplot\n",
        "\n",
        "def shapiro_qq_plot(df):\n",
        "    #Shapiro 통계량이 높으면 정규분포에 더 근접하지만 그렇다고 무조건 acc도 올라가지는 않는다.\n",
        "    '''\n",
        "    Args:\n",
        "        df['target']\n",
        "\n",
        "    Returns:\n",
        "        qq_plot and Shapiro statics of df['target']\n",
        "        with [raw, sqrt, log, log1p] transformations\n",
        "    '''\n",
        "    \n",
        "    # 경고메세지 끄기\n",
        "    import warnings\n",
        "    warnings.filterwarnings(action='ignore')\n",
        "\n",
        "    f, axs = plt.subplots(2,2,figsize=(10,10))\n",
        "    f.suptitle('shapiro_qq_plot', fontsize=25)\n",
        "\n",
        "    df_list = [(df,'RAW'), (np.sqrt(df),'SQRT'), (np.log(df),'LOG'), (np.log1p(df),'LOG1P')]\n",
        "\n",
        "    for data, ax in zip(df_list, axs.ravel()):\n",
        "        #qq plot 그리기\n",
        "        probplot(data[0], dist=stats.norm(), plot=ax)\n",
        "\n",
        "        #정규화 변환 방법 title로 설정\n",
        "        ax.set_title(data[1], size=20)\n",
        "\n",
        "        #shapiro 통계량, p-value 반올림 xlabel설정\n",
        "        statics = np.round(stats.shapiro(data[0])[:],3)\n",
        "        ax.set_xlabel(f'static:{statics[0]}, p-value: {statics[1]}',size=15)\n",
        "\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kGIuRKMs5Ypw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bar그래프에 수치 넣기 함수"
      ],
      "metadata": {
        "id": "xJsEAezKK-5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_percent(ax, total_size):\n",
        "    for patch in ax.patches:\n",
        "        height = patch.get_height()\n",
        "        width = patch.get_width()\n",
        "        left_coord = patch.get_x()\n",
        "        percent = height / total_size * 100\n",
        "\n",
        "        ax.text(x = left_coord + width / 2.0,\n",
        "                y = height + total_size * 0.001,\n",
        "                s = f'{percent:1.1f}%',\n",
        "                ha = 'center')"
      ],
      "metadata": {
        "id": "b7YGqE0JLCHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##gridspec 사용법"
      ],
      "metadata": {
        "id": "DZ0T5n3O1vEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# 틀 준비\n",
        "mpl.rc('font', size = 12)\n",
        "grid = gridspec.GridSpec(3, 2)\n",
        "plt.figure(figsize=(10,16))\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
        "\n",
        "# 서브플롯 그리기\n",
        "bin = ['bin_0','bin_1','bin_2','bin_3','bin_4']\n",
        "\n",
        "for idx, feature in enumerate(bin):\n",
        "    ax = plt.subplot(grid[idx])\n",
        "\n",
        "    sns.countplot(x = feature,\n",
        "                  data = df,\n",
        "                  hue = 'target',\n",
        "                  palette = 'pastel',\n",
        "                  ax = ax)\n",
        "    ax.set_title(f'{feature} Distribution by Target')\n",
        "    write_percent(ax, len(df))"
      ],
      "metadata": {
        "id": "ib_f6up21vEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pointplot crosstab taget 비율"
      ],
      "metadata": {
        "id": "Pgf7jHA49rP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_crosstab(df, feature):\n",
        "    crosstab = pd.crosstab(df[feature], df['target'], normalize='index') * 100\n",
        "    crosstab = crosstab.reset_index()\n",
        "    return crosstab\n",
        "\n",
        "def plot_pointplot(ax, feature, crosstab):\n",
        "    ax2 = ax.twinx() # x축은 공유하고 y축은 공유하지 않는 새로운 축 생성\n",
        "    # 새로운 축에 포인트플롯 그리기\n",
        "    ax2 = sns.pointplot(x=feature, y=1, data=crosstab,\n",
        "                        order=crosstab[feature].values, # 포인트플롯 순서\n",
        "                        color='black',                  # 포인트플롯 색상\n",
        "                        legend=False)                   # 범례 미표시\n",
        "    ax2.set_ylim(crosstab[1].min()-5, crosstab[1].max()*1.1) # y축 범위 설정\n",
        "    ax2.set_ylabel('Target 1 Ratio(%)')\n",
        "\n",
        "def write_percent(ax, total_size):\n",
        "    for patch in ax.patches:\n",
        "        height = patch.get_height()\n",
        "        width = patch.get_width()\n",
        "        left_coord = patch.get_x()\n",
        "        percent = height / total_size * 100\n",
        "\n",
        "        ax.text(x = left_coord + width / 2.0,\n",
        "                y = height + total_size * 0.001,\n",
        "                s = f'{percent:1.1f}%',\n",
        "                ha = 'center')\n",
        "\n",
        "def plot_cat_dist_with_true_ratio(df, features, num_rows, num_cols, \n",
        "                                  size=(15, 20)):\n",
        "    plt.figure(figsize=size)  # 전체 Figure 크기 설정\n",
        "    grid = gridspec.GridSpec(num_rows, num_cols) # 서브플롯 배치\n",
        "    plt.subplots_adjust(wspace=0.45, hspace=0.3) # 서브플롯 좌우/상하 여백 설정\n",
        "    \n",
        "    for idx, feature in enumerate(features): \n",
        "        ax = plt.subplot(grid[idx])\n",
        "        crosstab = get_crosstab(df, feature) # 교차분석표 생성\n",
        "\n",
        "        # ax축에 타깃값 분포 카운트플롯 그리기\n",
        "        sns.countplot(x=feature, data=df,\n",
        "                      order=crosstab[feature].values,\n",
        "                      color='skyblue',\n",
        "                      ax=ax)\n",
        "\n",
        "        write_percent(ax, len(df)) # 비율 표시\n",
        "       \n",
        "        plot_pointplot(ax, feature, crosstab) # 포인트플롯 그리기\n",
        "        \n",
        "        ax.set_title(f'{feature} Distribution') # 그래프 제목 설정"
      ],
      "metadata": {
        "id": "I3tdNXlT9yDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sns.barplot 타겟별 비율 신뢰구간"
      ],
      "metadata": {
        "id": "ES-ahrXxDxbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def plot_target_ratio_by_features(df, features, num_rows, num_cols, \n",
        "                                  size=(12, 18)):\n",
        "    mpl.rc('font', size=9) \n",
        "    plt.figure(figsize=size)                     # 전체 Figure 크기 설정\n",
        "    grid = gridspec.GridSpec(num_rows, num_cols) # 서브플롯 배치\n",
        "    plt.subplots_adjust(wspace=0.3, hspace=0.3)  # 서브플롯 좌우/상하 여백 설정\n",
        "\n",
        "    for idx, feature in enumerate(features):\n",
        "        ax = plt.subplot(grid[idx])\n",
        "        # ax축에 고윳값별 타깃값 1 비율을 막대 그래프로 그리기\n",
        "        sns.barplot(x=feature, y='target', data=df, palette='Set2', ax=ax)"
      ],
      "metadata": {
        "id": "eey4sVdLDomM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 연속형변수(float) train test의 hist분포와 타겟변수의 scatter분포"
      ],
      "metadata": {
        "id": "Zu0ZICH8TmS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_cols = summary[summary['데이터타입'] == 'float32'].index\n",
        "\n",
        "plt.figure(figsize=(12, 12))                # Figure 크기 설정\n",
        "grid = gridspec.GridSpec(4,4)              # GridSpec 객체 생성\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.3) # 서브플롯 간 여백 설정\n",
        "first_ax = True    #첫 ax에 legend를 넣기 위한 bool값\n",
        "\n",
        "for idx, f in enumerate(float_cols):\n",
        "    ax = plt.subplot(grid[idx])\n",
        "\n",
        "    #최소 최대 값으로 그래프 간격 만들기\n",
        "    mi = min(train_cut[f].min(), test[f].min())\n",
        "    ma = max(train_cut[f].max(), test[f].max())\n",
        "    bins = np.linspace(mi, ma, 50)\n",
        "\n",
        "    #train test의 hist분포\n",
        "    ax.hist(train_cut[f], bins=bins, alpha=0.5, density=True, label='train_cut')\n",
        "    ax.hist(test[f], bins=bins, alpha=0.5, density=True, label='test')\n",
        "    ax.set_xlabel(f)\n",
        "    if first_ax:\n",
        "        ax.legend(loc='lower left')\n",
        "    \n",
        "    #x축을 기준으로 복사하여 타겟값의 확률을 scatter분포\n",
        "    ax2 = ax.twinx()\n",
        "    total, _ = np.histogram(train_cut[f], bins=bins)\n",
        "    failures, _ = np.histogram(train_cut[f][train_cut.failure == 1], bins=bins)\n",
        "    with warnings.catch_warnings(): # ignore divide by zero for empty bins\n",
        "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "        ax2.scatter((bins[1:] + bins[:-1]) / 2, failures / total,\n",
        "                    color='m', s=10, label='failure probability')\n",
        "    ax2.set_ylim(0, 0.5)\n",
        "    ax2.tick_params(axis='y', colors='m')\n",
        "    if first_ax:\n",
        "        ax2.legend(loc='upper right')\n",
        "        first_ax = False\n",
        "\n",
        "plt.tight_layout(w_pad=1)\n",
        "plt.suptitle('train_cut and test distributions of the continuous features', fontsize=20, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M7pdpFtdTwSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tfidf cosine_similarity heatmap"
      ],
      "metadata": {
        "id": "sxSFo-_IF_ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer().fit_transform(shops['상점명'].to_list()).toarray()\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "tf = pd.DataFrame(tf)\n",
        "\n",
        "df = pd.DataFrame(cosine_similarity(tf,tf))\n",
        "\n",
        "#유사도 index 순위\n",
        "import re\n",
        "[re.sub('\\s+',' ',i).split() for i in str(df[df<(1-1e-6)].idxmax()).split('\\n')]\n",
        "\n",
        "plt.figure(figsize=(16,16)) \n",
        "sns.heatmap(df[df>0.5])"
      ],
      "metadata": {
        "id": "KCGCh2QvGEhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#히트맵 이쁘게 그리기\n",
        "correlations = train_samples.corr().abs()\n",
        "mask=np.triu(np.ones_like(correlations))\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(16,12))\n",
        "sns.heatmap(correlations, ax=ax, mask=mask, cmap='YlOrBr')\n",
        "ax.set_title(\"Correlation of features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aq31cRPJq-Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unstacked = correlations.unstack()\n",
        "unstacked = unstacked.sort_values(ascending=False, kind=\"quicksort\").drop_duplicates().head(25)\n",
        "unstacked"
      ],
      "metadata": {
        "id": "i5XCpR8SrDOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##lightgbm feature importance"
      ],
      "metadata": {
        "id": "CbFwP0nqnbTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import plot_importance\n",
        "plot_importance(lgb_model)"
      ],
      "metadata": {
        "id": "gFw9Cmx5nejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#피처엔지니어링"
      ],
      "metadata": {
        "id": "JNPz8GMzkY64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## product함수"
      ],
      "metadata": {
        "id": "1muLJpfJkaRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "[i for i in product('abc','def',range(2))]"
      ],
      "metadata": {
        "id": "PI2SH8eEkcIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#전처리"
      ],
      "metadata": {
        "id": "s1SgmPkK-BH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##인코딩"
      ],
      "metadata": {
        "id": "-Ef32J6pyWAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 레이블 인코더 생성\n",
        "label_encoder = LabelEncoder()\n",
        "# 도시 피처 레이블 인코딩\n",
        "shops['도시'] = label_encoder.fit_transform(shops['도시'])"
      ],
      "metadata": {
        "id": "b3LaQg9CyXPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###희소행렬 합치기"
      ],
      "metadata": {
        "id": "wG0UScTk6r18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data),\n",
        "               encoded_nom_matrix,\n",
        "               encoded_date_matrix],\n",
        "              format='csr')"
      ],
      "metadata": {
        "id": "a1ANU8vz6ufX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 스케일러"
      ],
      "metadata": {
        "id": "PLt_hman5_kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MinMax"
      ],
      "metadata": {
        "id": "gmcQqgxA6x2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ord_features = [i for i in all_data if i[:3] == 'ord']\n",
        "\n",
        "all_data[ord_features] = MinMaxScaler().fit_transform(all_data[ord_features])"
      ],
      "metadata": {
        "id": "QmH1s_FT6Ayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 베이스라인 모델링"
      ],
      "metadata": {
        "id": "ZPWzIpyNtUof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##분류"
      ],
      "metadata": {
        "id": "V-Ca10NotZz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LogisticRegression"
      ],
      "metadata": {
        "id": "LI_ksHpRtb3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logistic_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "zQlmFbYGtWAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lightgbm & kfold"
      ],
      "metadata": {
        "id": "OCMdurastexe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "oof_test_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X,y)):\n",
        "\n",
        "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
        "\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
        "\n",
        "    dtrain = lgb.Dataset(X_train, y_train)\n",
        "    dvalid = lgb.Dataset(X_valid, y_valid)\n",
        "\n",
        "    lgb_model = lgb.train(params=params,\n",
        "                          train_set=dtrain,\n",
        "                          num_boost_round=1000,        # 부스팅 횟수\n",
        "                          valid_sets=dvalid,\n",
        "                          feval=gini,                  # 검증용 평가지표\n",
        "                          early_stopping_rounds=100,   # 조기종료 조건\n",
        "                          verbose_eval=100)            # 100번째마다 점수 출력\n",
        "\n",
        "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
        "    \n",
        "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
        "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
        "    \n",
        "    # 검증 데이터 예측 확률에 대한 정규화 지니계수 \n",
        "    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')"
      ],
      "metadata": {
        "id": "SiCBu2WFFG44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 하이퍼 파라미터 최적화"
      ],
      "metadata": {
        "id": "Vc8IivnX9yPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV"
      ],
      "metadata": {
        "id": "h9e3O47193Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "lr_params = {'C':[0.1, 0.125, 0.2], 'max_iter':[800, 900, 1000], \n",
        "             'solver':['liblinear'], 'random_state':[42]}\n",
        "\n",
        "# 그리드서치 객체 생성\n",
        "gridsearch_logistic_model = GridSearchCV(estimator=logistic_model,\n",
        "                                         param_grid=lr_params,\n",
        "                                         scoring='roc_auc', # 평가지표\n",
        "                                         cv=5)\n",
        "# 그리드서치 수행\n",
        "gridsearch_logistic_model.fit(X_train, y_train)\n",
        "\n",
        "print('최적 하이퍼파라미터:', gridsearch_logistic_model.best_params_)"
      ],
      "metadata": {
        "id": "rZMY00eZ95-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##베이지안최적화"
      ],
      "metadata": {
        "id": "hucWl9PHUr8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lightgbm 모델"
      ],
      "metadata": {
        "id": "r3i_5ZMKPc85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_gini(y_true, y_pred):\n",
        "    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n",
        "    assert y_true.shape == y_pred.shape\n",
        "\n",
        "    n_samples = y_true.shape[0]                      # 데이터 개수\n",
        "    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n",
        "\n",
        "    # 1) 예측값에 대한 지니계수\n",
        "    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n",
        "    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
        "    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n",
        "\n",
        "    # 2) 예측이 완벽할 때 지니계수\n",
        "    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n",
        "    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n",
        "    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n",
        "\n",
        "    # 정규화된 지니계수\n",
        "    return G_pred / G_true\n",
        "\n",
        "def gini(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'gini', eval_gini(labels, preds), True # 반환값"
      ],
      "metadata": {
        "id": "jz0RBzpjQGUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
        "                  bagging_fraction, min_child_samples, min_child_weight):\n",
        "    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n",
        "    \n",
        "    # 베이지안 최적화를 수행할 하이퍼파라미터 \n",
        "    params = {'num_leaves': int(round(num_leaves)),\n",
        "              'lambda_l1': lambda_l1,\n",
        "              'lambda_l2': lambda_l2,\n",
        "              'feature_fraction': feature_fraction,\n",
        "              'bagging_fraction': bagging_fraction,\n",
        "              'min_child_samples': int(round(min_child_samples)),\n",
        "              'min_child_weight': min_child_weight,\n",
        "              'feature_pre_filter': False}\n",
        "    # 고정된 하이퍼파라미터도 추가\n",
        "    params.update(fixed_params)\n",
        "    \n",
        "    print('하이퍼파라미터:', params)    \n",
        "    \n",
        "    # LightGBM 모델 훈련\n",
        "    lgb_model = lgb.train(params=params, \n",
        "                           train_set=bayes_dtrain,\n",
        "                           num_boost_round=2500,\n",
        "                           valid_sets=bayes_dvalid,\n",
        "                           feval=gini,\n",
        "                           early_stopping_rounds=300,\n",
        "                           verbose_eval=False)\n",
        "    # 검증 데이터로 예측 수행\n",
        "    preds = lgb_model.predict(X_valid) \n",
        "    # 지니계수 계산\n",
        "    gini_score = eval_gini(y_valid, preds)\n",
        "    print(f'지니계수 : {gini_score}\\n')\n",
        "    \n",
        "    return gini_score"
      ],
      "metadata": {
        "id": "qAP1_P9bVMQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# 베이지안 최적화 객체 생성\n",
        "optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n",
        "                                 pbounds=param_bounds, # 하이퍼파라미터 범위\n",
        "                                 random_state=0)\n",
        "optimizer.maximize(init_points=3, n_iter=6)"
      ],
      "metadata": {
        "id": "OS_mPfv-UvUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xgboost 모델"
      ],
      "metadata": {
        "id": "5-GnwWdZPo_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'gini', eval_gini(labels, preds)"
      ],
      "metadata": {
        "id": "O8n1aM92QRPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
        "param_bounds = {'max_depth': (4, 8),\n",
        "                'subsample': (0.6, 0.9),\n",
        "                'colsample_bytree': (0.7, 1.0),\n",
        "                'min_child_weight': (5, 7),\n",
        "                'gamma': (8, 11),\n",
        "                'reg_alpha': (7, 9),\n",
        "                'reg_lambda': (1.1, 1.5),\n",
        "                'scale_pos_weight': (1.4, 1.6)}\n",
        "\n",
        "# 값이 고정된 하이퍼파라미터\n",
        "fixed_params = {'objective': 'binary:logistic',\n",
        "                'learning_rate': 0.02,\n",
        "                'random_state': 1991}"
      ],
      "metadata": {
        "id": "fH0fl3jQPmqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n",
        "                 reg_alpha, gamma, reg_lambda, scale_pos_weight):\n",
        "    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n",
        "    # 베이지안 최적화를 수행할 하이퍼파라미터\n",
        "    params = {'max_depth': int(round(max_depth)),\n",
        "              'subsample': subsample,\n",
        "              'colsample_bytree': colsample_bytree,\n",
        "              'min_child_weight': min_child_weight,\n",
        "              'gamma': gamma,\n",
        "              'reg_alpha':reg_alpha,\n",
        "              'reg_lambda': reg_lambda,\n",
        "              'scale_pos_weight': scale_pos_weight}\n",
        "    # 값이 고정된 하이퍼파라미터도 추가\n",
        "    params.update(fixed_params)\n",
        "    \n",
        "    print('하이퍼파라미터 :', params)    \n",
        "        \n",
        "    # XGBoost 모델 훈련\n",
        "    xgb_model = xgb.train(params=params, \n",
        "                          dtrain=bayes_dtrain,\n",
        "                          num_boost_round=2000,\n",
        "                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n",
        "                          maximize=True,\n",
        "                          feval=gini,\n",
        "                          early_stopping_rounds=200,\n",
        "                          verbose_eval=False)\n",
        "                           \n",
        "    best_iter = xgb_model.best_iteration # 최적 반복 횟수\n",
        "    # 검증 데이터로 예측 수행\n",
        "    preds = xgb_model.predict(bayes_dvalid, \n",
        "                              iteration_range=(0, best_iter))\n",
        "    # 지니계수 계산\n",
        "    gini_score = eval_gini(y_valid, preds)\n",
        "    print(f'지니계수 : {gini_score}\\n')\n",
        "    \n",
        "    return gini_score"
      ],
      "metadata": {
        "id": "Lc-u13q0PvZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화 객체 생성\n",
        "optimizer = BayesianOptimization(f=eval_function, \n",
        "                                 pbounds=param_bounds, \n",
        "                                 random_state=0)\n",
        "\n",
        "# 베이지안 최적화 수행\n",
        "optimizer.maximize(init_points=3, n_iter=6)"
      ],
      "metadata": {
        "id": "GgUrY1f4Pwc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#평가지표"
      ],
      "metadata": {
        "id": "sZrW2550tg4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## roc auc\n"
      ],
      "metadata": {
        "id": "qBRaFgAttiKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc = roc_auc_score(y_valid, y_valid_preds)\n",
        "print(f'검증 데이터 ROC AUC : {roc_auc:.4f}')"
      ],
      "metadata": {
        "id": "qUOs3P0qtjbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}